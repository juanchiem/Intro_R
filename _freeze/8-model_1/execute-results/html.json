{
  "hash": "9775e7d1fc3282e4fe009495da9cf1ca",
  "result": {
    "markdown": "\n\n\n# Regresión\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-2_c39ef0770cab6267656731d9bc92d88c'}\n\n```{.r .cell-code}\npacman::p_load(\n  \n  # usos generales\n  tidyverse, \n  \n  # exploracion\n  skimr,\n  GGally, \n  # correlation, #easystats \n\n  # modelado \n  \n  ## easystats https://easystats.github.io/easystats/\n  # performance,\n  # modelbased,\n  # see,\n  # parameters, \n  easystats, # carga todos\n\n  relaimpo, \n  ggeffects,\n  sjPlot \n)\n\nconflicted::conflict_prefer(\"filter\", \"dplyr\")\nconflicted::conflict_prefer(\"select\", \"dplyr\")\n```\n:::\n\n\n## Regresión lineal simple\n\n$$\\underbrace{Y}_{\\substack{\\text{variable} \\\\ \\text{aleatoria}}} = f(X)=\\underbrace{\\beta_0 + \\beta_1 X}_{\\text{sistematico}} + \\underbrace{\\varepsilon}_{\\text{aleatorio}}$$ El componente sistemático captura la relación lineal entre las variables independientes y la variable dependiente y es utilizado para hacer predicciones o estimaciones de la variable dependiente en función de los valores de las variables independientes.\n\nEl componente sistemático no tiene en cuenta los posibles errores o perturbaciones en los datos, los cuales se modelan mediante el término de error del modelo.\n\n![](fig_3/slr.png){fig-align=\"center\" width=\"400px\"}\n\nEl caso del modelo lineal simple tiene 2 parámetros, el **intercepto** y la **pendiente**, el primero representa el valor de la respuesta cuando X = 0. La pendiente representa el cambio de Y por cada cambio unitario de X. Si la pendiente no es distinta de 0, entonces no hay relación entre X e Y.\n\n![](fig_3/slr_assump.png){fig-align=\"center\" width=\"400px\"}\n\nLa línea recta resume la relación lineal entre la expectativa de Y y cada valor de X. También vemos que cada observación (puntos) es una realización de una variable aleatoria con distribución normal con expectativa condicionada por X y varianza constante.\n\n-   **Supuestos**\n\n(Los pondremos a prueba con el paquete [performance](https://easystats.github.io/performance/articles/check_model.html))\n\n1 - **Relación lineal de las variables**.\n\nGráfico de Residuales vs Ajustados por el modelo. Una línea horizontal, sin patrones definidos, indicaría relación lineal.\n\n2 - Los errores son variables aleatorias **independientes** con **distribución normal**\n\n$$e_\\text{iid} \\sim N(0,\\sigma^2_\\varepsilon)$$\n\nGráfico Q-Q normal. Los puntos residuales deberían seguir la línea recta diagonal.\n\n3 - **Homogeneidad de varianza** de los residuos (homocedasticidad)\n\nGráfico Scale-Location (o Spread-Location). La línea horizontal con puntos igualmente separados es una buena indicación de homocedasticidad.\n\n4 - Identificar **casos influyentes**, es decir, valores extremos que pueden influir en los resultados de la regresión cuando se incluyen o excluyen del análisis. Esta trama se describirá más adelante en las próximas secciones.\n\n5 - Ausencia de **Multicolinealidad**. Colinealidad significa que una cantidad sustancial de información contenida en algunas de los predictoras se puede unir como una función lineal de algunos de otra predictora del modelo.\n\n-   **Performance del modelo**\n\n-   RMSE: La raíz del error cuadrático medio. Esto mide la diferencia promedio entre las predicciones hechas por el modelo y las observaciones reales. Cuanto **menor** sea el RMSE, más fielmente podrá un modelo predecir las observaciones reales.\n\n-   R2: Medida de la correlación entre las predicciones hechas por el modelo y las observaciones reales. Cuanto **mayor** sea el R-cuadrado, más fielmente podrá un modelo predecir las observaciones reales.\n\n## Regresión lineal múltiple\n\nGeneralización de la regresión lineal simple al caso de más de una variable independiente, y es un caso particular del modelo lineal general, restringido a una única variable dependiente. El modelo básico de regresión lineal múltiple es:\n\n$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_pX_p + \\varepsilon$$ $X$s **pueden ser**:\n\n-   variables cuantitativas (y sus transformaciones)\n-   variables categóricas (como variables dummys 0/1)\n-   productos cruzados de las mismas variables (potencias), o diferentes variables (interacciones)\n\n$X$s **no puede ser**:\n\n-   funciones lineales perfectas de otras predictoras\n\n## Estudio de caso: trigo diploide\n\n![](fig_3/Triticum_monococcum0.jpg){fig-align=\"center\" width=\"300px\"}\n\nSe midieron varios rasgos morfológicos de 190 semillas seleccionadas al azar de una línea de trigo diploide (*Triticum monococcum*). [(Jing et al., 2007)](http://www.wgin.org.uk/information/documents/WGIN%20publications%20pdfs/Jing%202007.pdf)\n\nEl objetivo era *identificar variables asociadas con diferencias en el peso de las semillas*\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-3_9ccf200a51c82f9b6c030bcced0e0076'}\n\n```{.r .cell-code}\ntriticum <- rio::import(\"https://raw.githubusercontent.com/juanchiem/agro_data/master/triticum_monococcum.txt\")\nhead(triticum)\n```\n:::\n\n\n::: callout-note\n## Challenge\n\n-   Exporte triticum a su carpeta \"data\" en formato .csv\n\n-   Importelos nuevamente ahora desde su propia carpeta \"data\"\n:::\n\nLas variables medidas fueron: 'peso' (mg), 'diámetro' (mm), 'longitud' (mm), 'contenido de humedad' (%) y 'dureza' del endosperma (valor índice del sistema de caracterización de grano único)\n\n### Exploración\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-4_cbad128d96809fb82e40005b55b90684'}\n\n```{.r .cell-code}\nstr(triticum)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-5_537bb654c21c8593c91354ef59bc665f'}\n\n```{.r .cell-code}\ntriticum %>% \n  skim()\n```\n:::\n\n\n¿Existen correlaciones entre las variables?\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-6_f9c8251e842e8ce5be63555ad18a0fe0'}\n\n```{.r .cell-code}\ntriticum %>% \n  select(-ID)  %>% \n  ggpairs() +\n  theme_bw()\n```\n:::\n\n\nSi lo prefieren en modo tabla:\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-7_edf6eee54c46cae4bcdfdd6720c04175'}\n\n```{.r .cell-code}\ntriticum %>%\n  select(-ID)  %>% \n  correlation()\n```\n:::\n\n\n### Ajuste de modelo\n\n#### Regresión lineal simple\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-8_1b7f52735490666be5f2af593dbcab66'}\n\n```{.r .cell-code}\nm_ls <- lm(\n  weight ~ diameter, \n  data = triticum\n)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-9_5aaa75b2187ae5fcbc6f809f7fe31b3b'}\n\n```{.r .cell-code}\n# check_model(m0)\ncheck_normality(m_ls)\ncheck_heteroscedasticity(m_ls)\n```\n:::\n\n\nSignificancia de los parametros\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-10_2d9b777c3d2e95b9cf01521fc44bfcbb'}\n\n```{.r .cell-code}\nanova(m_ls)\n```\n:::\n\n\nCoeficientes\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-11_e6da53ec3ffb9884b31d229393fb0fc6'}\n\n```{.r .cell-code}\nsummary(m_ls)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-12_df8bbdec1694f49c5819fb3c52ea623c'}\n\n```{.r .cell-code}\ncheck_predictions(m_ls)\nperformance_accuracy(m_ls)\n```\n:::\n\n\n#### Regresión lineal múltiple\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-13_00a9d768b8f3f242aaceb0493ea49bc0'}\n\n```{.r .cell-code}\nm1 <- lm(\n  weight ~ length + diameter + hardness + moisture, \n  data = triticum\n)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-14_b0a28a2b71d55da4b388b90aeda55a51'}\n\n```{.r .cell-code}\ncheck_normality(m1)\ncheck_heteroscedasticity(m1)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-15_b359ec6e804bc7da8d0dbb6325b12590'}\n\n```{.r .cell-code}\nanova(m1)\n# summary(m1)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-16_6afd82fa30c1096c085123a9229e9410'}\n\n```{.r .cell-code}\nmodel_parameters(m1)\n```\n:::\n\n\nReajustar modelo\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-17_e5a175f4c4f75d2b42900da171fdf9a2'}\n\n```{.r .cell-code}\nm2 <- lm(\n  weight ~ length + diameter + hardness, \n  data = triticum\n)\n# m2 <- update(m1, . ~ . -moisture)\ncompare_performance(m1, m2)\n```\n:::\n\n\nSe redujo AIC, RMSE y aumentó R2 ajustado\n\n### Chequeo de supuestos\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-18_b71aee143c447511e431ed0ed9f54542'}\n\n```{.r .cell-code}\ncheck_model(m2)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-19_2e780fed9136b3b008fb6939d084e078'}\n\n```{.r .cell-code}\n# plot 1 - ¿Que capacidad predictiva tiene el modelo?\ncheck_predictions(m_ls)\n\n# plot 2 - ¿Queda algún patrón en los residuales?\ncheck_model(m2, check = \"ncv\")\n  \n# plot 3 - ¿Son sus varianzas constantes?\ncheck_heteroscedasticity(m2) %>% plot\n\n# plot 4 - ¿Hay valores influyentes?\n# check_model(m2, check = \"binned_residuals\")\n\n# plot 5 - ¿Presencia de multicolinearidad?\n# VIF > 10 indica seria grave multicolinearidad \ncheck_collinearity(m2) %>% plot\n\n# plot 6 - ¿Están los errores normalmente distribuidos?\ncheck_normality(m2)\n```\n:::\n\n\nComo era de esperar, `longitud` y `diámetro` tienen un VIF enorme.\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-20_825111775cf29995d11b2c43dbf8002c'}\n\n```{.r .cell-code}\nm3 <- lm(\n  weight ~ diameter + hardness, \n  data = triticum\n)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-21_c2d1fde7366ca0b0ea788c2c8b0381b1'}\n\n```{.r .cell-code}\n# performance::\ncheck_collinearity(m3) # corregimos multcol!\nperformance_accuracy(m3)\n# compare_models(m2, m3)\ncompare_performance(m2, m3)# se ve que no se gana en precision pero el m2 tenia colinealidad\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-22_6c73dec2af90d2d81c0eecd415a772d5'}\n\n```{.r .cell-code}\nanova(m3)\nsummary(m3)\n```\n:::\n\n\n[{sjPlot}](https://strengejacke.github.io/sjPlot/index.html)\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-23_b08eb18626dccc2762024e89f774c249'}\n\n```{.r .cell-code}\ntab_model(m3)\n```\n:::\n\n\n-   Alrededor del 80% de la variabilidad del \"peso\" de la semilla se explica por el modelo que tiene \"diámetro\" y \"dureza\" como predictores\n\n### Contribucion de variables predictoras\n\n[{relaimpo}](https://rdrr.io/cran/relaimpo/man/calc.relimp.html)\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-24_0afb9f33923c7418e4497f0c0ade0674'}\n\n```{.r .cell-code}\n# relaimpo::\nri_m <- calc.relimp(m3, type =  \"car\", rela = TRUE )  \nri_m\nplot(ri_m)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-25_7cd47fa986c6a0a5beff91d857a219d4'}\n\n```{.r .cell-code}\nperformance_accuracy(m3, method = \"cv\")\n```\n:::\n\n\n### Predicciones\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-26_c72b063f5f8bc0bec913b3fb08f90276'}\n\n```{.r .cell-code}\ncheck_predictions(m3)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-27_11038daa34b59a86e064de0772773381'}\n\n```{.r .cell-code}\n# modelbased::\nestimate_relation(m3) %>% \n  plot(ribbon = list(alpha = 0)) # Make CI ribbon transparent for clarity\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-28_b700c451b7ef0b211129e5bacefc0904'}\n\n```{.r .cell-code}\n# sjPlot::  \nplot_model(m3, type = \"pred\", terms = c(\"diameter\", \"hardness\"))\nplot_model(m3, type = \"pred\", terms = c(\"hardness\", \"diameter\"))\n# Se nota la mayor importancia de `diameter`en este grafico no?\n```\n:::\n\n\nCuánto será el peso del grano si tengo diameter=2.5 y hardness=-1\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-29_483ee613e06893f3adf430fd582f8b64'}\n\n```{.r .cell-code}\n#ggeffects::\nggpredict(m3, terms = c(\"diameter [2.5]\", \"hardness [-1]\"))\n```\n:::\n\n\nA modo anecdotico vemos una interaccion de 2 var continuas\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-30_f7c9189484fbc08d6f07e2e23a2c41d6'}\n\n```{.r .cell-code}\nm4 <- lm(\n  weight ~ diameter * hardness, \n  data = triticum\n)\n\nanova(m4)\nsummary(m4)\ncompare_performance(m3, m4)\n\npreds4 <- estimate_relation(m4)\nplot(preds4, ribbon = list(alpha = 0)) # Make CI ribbon transparent for clarity\n```\n:::\n\n\n::: callout-note\n## Xtra\n\nPara validar un modelo es recomendable entrenarlo con un set de datos diferente del cual se haran las predicciones - validacion cruzada\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-31_53cad1a573c487d4306ed5975ab57ed4'}\n\n```{.r .cell-code}\n# Create train and test dataset\ntrain <- triticum %>% sample_frac(.70)\ntest <- anti_join(triticum, train, by = 'ID')\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-32_2daadf5d742a4b22f8168dfe2374997f'}\n\n```{.r .cell-code}\n# ajustamos los modelos con el train dataset\nm0_1 <- lm(weight ~ diameter, data = train)\nm3_1 <- lm(weight ~ diameter + hardness, data = train)\n\n# colocamos las predicciones de cada modelo junto las observaciones reales\ntest <- test %>% mutate(pred_rls = predict(m0_1, test),\n                        pred_rlm = predict(m3_1, test))\n```\n:::\n\n\nLa performance de los modelos se evalua con las siguientes métricas:\n\n-   RMSE: La raíz del error cuadrático medio. Esto mide la diferencia promedio entre las predicciones hechas por el modelo y las observaciones reales. Cuanto menor sea el RMSE, más fielmente podrá un modelo predecir las observaciones reales.\n\n-   Rsquared: Esta es una medida de la correlación entre las predicciones hechas por el modelo y las observaciones reales. Cuanto mayor sea el R-cuadrado, más fielmente podrá un modelo predecir las observaciones reales.\n\n-   MAE: El error absoluto medio. Esta es la diferencia absoluta promedio entre las predicciones hechas por el modelo y las observaciones reales. Cuanto más bajo es el MAE, más cerca puede un modelo predecir las observaciones reales\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-33_60803e199356340a829918085243d836'}\n\n```{.r .cell-code}\nlibrary(caret)\ndata.frame(R2 = R2(test$pred_rls, test$weight),\n            RMSE = RMSE(test$pred_rls, test$weight),\n            MAE = MAE(test$pred_rls, test$weight))\n\ndata.frame(R2 = R2(test$pred_rlm, test$weight),\n            RMSE = RMSE(test$pred_rlm, test$weight),\n            MAE = MAE(test$pred_rlm, test$weight))\n```\n:::\n\n\nVemos mayor R2 y menor RMSE y MAE con `rlm`\n:::\n\n## Regresión polinomial\n\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-34_5be5d03bb9fafb880a4c3c3123857e6d'}\n\n```{.r .cell-code}\ndf <- data.frame(\n  hours = c(7.7,8.7,10.7,14.1,\n            7,14,14.4,11.6,11.3,5.6,7.1,6.8,11.9,8.8,\n            12.7,10,12.2,14.9,8.8,12.8,14.3,7.1,11.5,\n            6.3,7.7,8.9,5.1,8.8,13.7,8.4,9.8,11,9.9,6.9,\n            13.3,11.7,12.9,6.1,12.2,9.1,13.2,11.5,12.8,\n            10.5,10.3,12.9,5.2,9.8,12.3,11.9),\n  score = c(64.3,70.7,73.7,\n            86.1,59.8,83.6,89.1,78.1,78.4,59.1,65.9,60.8,\n            78.5,66.4,84.6,69.2,80,98.5,64.1,87.9,88.9,\n            65.5,75.7,60,64.3,71.4,60.5,66.8,91.5,70.4,\n            70.4,77.7,70.4,61.2,88.9,74.7,86.6,58.3,77.5,\n            65.5,81.7,72.2,85.1,77.5,75.6,87.5,58.6,70,\n            84.8,80.5)\n)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-35_fb5133159ded2b66c3da3d5b8644dcae'}\n\n```{.r .cell-code}\np1 <- df %>%\n  ggplot()+\n  aes(hours, score)+\n  geom_point()\n\np1\n\np1 +  geom_smooth()\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-36_58c26a8192648982711d787b8f3be3d3'}\n\n```{.r .cell-code}\np1 + \n  geom_smooth(method = lm)+\n  geom_smooth(method = lm, formula = y ~ poly(x, 2), col=\"red\")\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-37_4f6001391d361a5fb107df77bb3c2ee7'}\n\n```{.r .cell-code}\nbase <- lm(score ~ poly(hours,1, raw=F), data=df)\ncheck_model(base, check=\"linearity\")\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-38_5ab1cfcead99ac20a243ca0c0c9054a4'}\n\n```{.r .cell-code}\nquad <- lm(score ~ poly(hours,2, raw=F), data=df)\ncheck_model(quad, check=\"linearity\")\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-39_31210fa088fff14378695e3b778adb83'}\n\n```{.r .cell-code}\ncompare_performance(base, quad)\nsummary(quad)\n```\n:::\n\n::: {.cell hash='8-model_1_cache/html/unnamed-chunk-40_0cdf1c7c82d008bcb9742b05b6de526f'}\n\n```{.r .cell-code}\nestimate_relation(quad) %>% \n  plot(ribbon = list(alpha = .2)) + \n  theme_bw() \n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}